# Abstract Open Science Festival (max 350 words, deadline 11 July)

## Tracking Research Objects: Levelling the playing field in research assessment

_Authors/Session Leads: Esther Plomp, Meron Vermaas, Carlos Martinez, Nemo Andrea

Including Open Science practices in the evaluation of researcher performance is currently a contested subject within academia and a topic on the agenda of several initatives already that try to change research assessment (such as [COARA](https://coara.eu/agreement/the-commitments/), [Adore declaration](https://adore.software/declaration/), [DORA](https://sfdora.org/), [Recognition & Rewards](https://recognitionrewards.nl/), and [Hidden REF](https://hidden-ref.org/)). 
Although many researchers contribute to their field of expertise in a multitude of manners, the most stringent criteria of success is the number of research articles published. 
Subverting the current “publish or perish” culture requires a novel approach to the assessment of research objects (such as software, data and methods) other than research articles. 
Appropriate tracking of research objects is a prerequisite for their assessment. 
However, despite infrastructure already being available to track research objects (such as the [Research Software Directory](https://research-software-directory.org/)) there is currently no standardised way to track and subsequently assess such research objects. 
This session aims to provide an overview of some of the existing developments and case studies (~20 minutes), as well as to provide a space to discuss our needs and requirements regarding the tracking of research objects (~40 minutes). 
This includes discussing questions such as: 
Should we track research objects or has this the risk to reinforce the publish or perish culture?
Are there any examples in the Netherlands where tracking of research objects have been successful? 
Can tracking of research objects incentivise researchers to share their research outputs in accordance with the FAIR principles, or do we need other tools? 
What technological infrastructure would be needed to effectively track research objects - Are there existing tools that can be adapted for this purpose? 
How can we balance quantitative and qualitative metrics in the evaluation of research objects? 
How can tracking research objects promote equity and inclusion within the research community? 
Please bring your examples, recommended practices and questions (and answers!) to the session!


# Session draft

14:55 - 15:40
Max 30 participants (capped by organisation)

~ 15 minutes case studies
Meron (5 min), also highlight the [flyer](https://docs.google.com/document/d/1RW1JcT48U-DYK_OnEJdcY0hUnr_wcBWAzsUDWOWnAvs/edit?usp=sharing)/[form](https://docs.google.com/forms/d/1JQtMFMM9IJs6EJRzCJNXwUBrq3Np5CYC-LzUVpnOKj0) to add examples of research object tracking (which can also be shared outside of the session)
Esther (5 min)
Announce intent to write blogpost for eScience center website
Esther to come up with instructions for group chairs/documenters

~ 20 minutes discussion (smaller groups that can each discuss a question for a while - move to a different one after a while + have a facilitator per question + summary at the end)
- Should we track research objects (what are the disadvantages?)? 
- In what way would tracking of research objects nurture a culture of sharing research outputs? 
- What (existing) technological infrastructure would be needed to effectively track research objects? (will this follow the FAIR principles? Do we need other tools?)
- How can we balance quantitative and qualitative metrics in the evaluation of research objects?
- What would you use research object tracking for? How can tracking research objects promote equity and inclusion within the research community?
- Question from audience?

Take notes in [shared document](https://docs.google.com/document/d/1AI3mQPdWorEjrbJgAzJArS2arRGkZ8vV5ZpB5YLyd0c/edit?usp=sharing).

~ 10 min recap

**Outcome:** blogpost to summarise the session (including recommendations that researchers could follow to ensure that their research outputs are easier to track?)

**Follow-ups after session (probably):** if needs are clear and there are simple steps that could be taken, perhaps some recommendations that researchers could follow to ensure that their research outputs are easier to track?

**Requirements:**
List of participants? Not possible due to GDPR - we can ask the participants about taking ownership during the session itself
Screen for case study presentations at start - check
Sheets/flipovers, markers, post-its - check
shared google doc for notes - Esther to set up

**Next meeting**
8 October, to further prep session and clarify details


